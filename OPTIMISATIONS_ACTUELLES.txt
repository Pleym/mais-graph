Optimisations / améliorations déjà appliquées (état actuel)
Date: 17/02/2026

1) Structuration du projet pour K1/K2/K3 (version de référence)
- Reprise du dépôt de base et recentrage sur:
  - K1: génération/CSR via from_edge_list
  - K2: BFS de référence (bfs_formal)
  - K3: SSSP de référence (Bellman-Ford: sssp_bf)
- Objectif: base stable et comparable avant d’ajouter des optimisations algorithmiques.

2) Nettoyage fonctionnel de l’exécution
- Point d’entrée main simplifié pour exécuter explicitement K1/K2/K3.
- Paramétrage d’exécution clair: ./main [scale] [edge_factor] [roots].
- Sortie standardisée des métriques K2/K3 (avg_time, teps) pour exploitation automatisée.

3) Scripts SLURM pour benchmark
- Ajout d’un script strong scaling:
  - kernel_1_2_experiments.sh
  - problème fixe, variation du nombre de threads (1..64)
- Ajout d’un script weak scaling:
  - kernel_weak_scaling.sh
  - augmentation de la taille (scale) en fonction du nombre de threads
- Ajout d’un script de comparaison de performance:
  - kernel_perf_compare.sh
  - comparaison REF vs OPT avec export CSV de speedup (K2/K3)

4) Instrumentation / traçabilité des résultats
- Création de dossiers de résultats dédiés par job:
  - results_strong_<jobid>
  - results_weak_<jobid>
  - results_perf_<jobid>
- Logs de runs par configuration (thread count / scale) conservés dans ces dossiers.
- Génération d’un speedup.csv pour la comparaison REF/OPT.

5) Nommage lisible des logs SLURM
- Strong: strong_%x_%j.out / strong_%x_%j.err
- Weak: weak_%x_%j.out / weak_%x_%j.err
- Perf: perf_%x_%j.out / perf_%x_%j.err
- Ajout d’un run_status.log dans chaque dossier results_* pour suivre l’avancement intra-job.

6) Variables d’environnement performance côté runtime
- Utilisation de:
  - OMP_NUM_THREADS=<t>
  - OMP_PROC_BIND=close
  - OMP_PLACES=cores
- But: meilleure stabilité des mesures et réduction du bruit d’ordonnancement.

7) Robustesse pratique des scripts
- Usage de set -euo pipefail pour capter rapidement les erreurs.
- Paramètres REF_BIN / OPT_BIN dans le script de comparaison (surcharge possible via sbatch --export).

Remarque
- Cette base est volontairement "référence + benchmark" pour quantifier proprement les gains.
- Les futures optimisations issues du PDF seront ajoutées ensuite dans le code BFS/SSSP et documentées ici avec:
  - principe,
  - impact attendu,
  - impact mesuré (speedup, efficacité, scalabilité).

8) Synthèse des optimisations identifiées dans le PDF (Reducing Communication in Parallel BFS on Distributed Memory Systems)
- Constat principal du papier:
  - En BFS distribué, le coût dominant devient la communication (collectives), surtout à grande échelle.
  - Le calcul local est relativement peu coûteux vs échanges réseau.
- Optimisation 1: "Sieving" (filtrage des données à envoyer)
  - Principe: éviter d’envoyer des éléments de frontier inutiles aux processus qui n’en ont pas besoin.
  - Le papier introduit une "cross directory" distribuée pour savoir quelles colonnes/partitions sont pertinentes.
  - Effet attendu: réduction du volume des messages avant communication.
- Optimisation 2: Compression bitmap
  - Principe: compresser les bitmaps de frontier (beaucoup de zéros) avant échange.
  - Exemple étudié: WAH (Word-Aligned Hybrid), avec bon compromis coût de compression / taux de réduction.
  - Effet attendu: réduction supplémentaire du volume transféré.
- Optimisation 3: Collectives adaptées
  - Remplacer des patterns de communication trop globaux (type allgather complet) par échanges plus ciblés (alltoallv + buffers compressés/filtrés).
  - Effet attendu: réduction du trafic inutile et meilleure scalabilité.

9) Intégration ciblée demandée (discussion "full top-down / full bottom-up / hybrid")
- Variante A: Full Top-Down
  - Frontier active -> exploration des voisins sortants.
  - Avantage: performant quand frontier petite (début BFS).
- Variante B: Full Bottom-Up
  - Parcours des non-visités et test d’adjacence vers frontier.
  - Avantage: performant quand frontier très large (milieu BFS sur graphes larges).
- Variante C: Hybrid (Direction-Optimizing)
  - Switch top-down <-> bottom-up selon heuristique (ex: m_f vs m_u).
  - Avantage: combine les points forts des deux approches.
- Méthode de comparaison prévue:
  - Mesurer K2 (temps BFS) pour Top-Down, Bottom-Up, Hybrid.
  - Comparer speedup vs référence sur mêmes jeux de paramètres (scale, edge factor, roots).

10) Remplacement / alternative à la logique type AML par OpenMP (sur cible mononoeud)
- Objectif pratique du projet actuel:
  - Prioriser l’optimisation intra-noeud via OpenMP (partage mémoire) plutôt que communication distribuée type AML.
- Plan technique:
  - Parallel for sur boucles d’exploration (voisins / sommets non visités).
  - Structures thread-safe pour frontier/next (bitset atomique, buffers locaux + fusion).
  - Contrôle d’affinité CPU (OMP_PROC_BIND, OMP_PLACES) déjà activé dans les scripts.
- Limite connue:
  - Sur un vrai run multi-noeuds, la réduction de communication inter-noeuds du papier nécessite une implémentation MPI/distribuée complète (cross-directory + compression + collectives ciblées).

11) Prochaines étapes d’implémentation (priorité)
- Étape 1: stabiliser 3 variantes BFS dans le code
  - bfs_full_top_down
  - bfs_full_bottom_up
  - bfs_hybrid
- Étape 2: instrumenter précisément les sorties
  - temps moyen K2 par variante
  - speedup vs bfs_formal
- Étape 3: ajouter une option "mode" au binaire
  - ex: ./main <scale> <edge_factor> <roots> <bfs_mode>
- Étape 4: (optionnel) prototype compression frontier pour scénario MPI
  - tester d’abord compression locale (bitmap -> WAH/RLE-like) pour valider le gain brut.

12) Implémentations ajoutées (code C/C++)
- BFS optimisé: bfs_top_down_omp_cas
  - Frontière niveau-par-niveau (top-down)
  - Visite atomique via compare_exchange (CAS) pour éviter les races sur parents[v]
  - Buffers locaux par thread pour construire next_frontier avec faible contention
- SSSP optimisé: sssp_bf_frontier_omp
  - Bellman-Ford à frontière active (on ne relaxe que les sommets modifiés)
  - Parallélisation OpenMP des sommets actifs
  - Verrous par sommet pour sécuriser les mises à jour concurrentes de distance/parent
- Main paramétrable par mode:
  - ref | bfs_opt | sssp_opt | all_opt | hybrid
  - Permet une comparaison progressive et logique des optimisations.

13) Pipeline d’évaluation optimisation par optimisation (Bash / SLURM)
- Nouveau script: kernel_optimization_pipeline.sh
  - Lance successivement ref -> bfs_opt -> sssp_opt -> all_opt -> hybrid
  - Fait varier les threads (1..64)
  - Exporte un CSV consolidé:
    threads, mode, k2_ms, k3_ms, k2_speedup_vs_ref, k3_speedup_vs_ref
  - Objectif: mesurer l’impact incrémental de chaque optimisation.
